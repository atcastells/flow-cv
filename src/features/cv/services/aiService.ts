import axios from 'axios';

// --- Type Definitions ---

export interface FunctionDefinition {
  name: string;
  description?: string;
  parameters: Record<string, unknown>; // JSON Schema object
}

export interface ToolDefinition {
  type: 'function';
  function: FunctionDefinition;
}

export interface ToolCall {
  id: string; // ID generated by the model, needed to match response
  type: 'function';
  function: {
    name: string;
    arguments: string; // JSON string of arguments
  };
}

// --- Types for Multimodal Content ---
// Represents a text part of the message content
export type TextPart = { type: "text"; text: string };

// Represents an image part of the message content
export type ImageUrl = { url: string; detail?: "low" | "high" | "auto" }; 
export type ImageUrlPart = { type: "image_url"; image_url: ImageUrl };

// A single part of the message content (either text or image)
export type ContentPart = TextPart | ImageUrlPart;

// --- Message Type ---

// Define the structure for UI components within messages
export interface UIComponentData {
  type: string; // e.g., 'skillSelector'
  props: Record<string, unknown>; // Component-specific properties
}

export interface Message {
  role: 'system' | 'user' | 'assistant' | 'tool';
  // Content can be a simple string, null (for tool calls), or an array for multimodal input
  content: string | null | ContentPart[] | React.ComponentType<unknown>;
  name?: string; // Optional: Used by some APIs for tool role to identify the function
  tool_calls?: ToolCall[]; // Present for assistant role when requesting calls
  tool_call_id?: string; // Required for tool role messages to match the call ID
  isLocal?: boolean; // Indicates if the message is local (not from the API)
  id?: string; // Optional: Unique ID for the message
  uiComponent?: UIComponentData; // Optional: Data for rendering a custom UI component
  suggestions?: string[]; // Optional: Suggestions for the user
}

// ChatCompletionRequest type
export interface ChatCompletionRequest {
  messages: Message[]; 
  model?: string;
  temperature?: number;
  max_tokens?: number;
  tools?: ToolDefinition[]; 
  tool_choice?: 'auto' | 'none' | 'required' | { type: 'function'; function: { name: string } }; 
}

// ChatCompletionResponseMessage type
export interface ChatCompletionResponseMessage extends Message {
    refusal?: unknown | null; 
}

// ChatCompletionResponse type
export interface ChatCompletionResponse {
  id?: string; 
  object?: string; 
  created?: number; 
  model?: string; 
  choices: {
    index?: number;
    message: ChatCompletionResponseMessage; 
    finish_reason: string | null; 
    logprobs?: unknown | null; 
  }[];
  usage?: { 
    prompt_tokens: number;
    completion_tokens: number;
    total_tokens: number;
  };
  provider?: string; 
}

// --- Service Implementation ---

const OPENROUTER_BASE_URL = 'https://openrouter.ai/api/v1';
const GROQ_BASE_URL = 'https://api.groq.com/openai/v1';
const LMStudio_BASE_URL = 'http://127.0.0.1:1234/v1';

const OPENROUTER_API_URL = `${OPENROUTER_BASE_URL}/chat/completions`;
const GROQ_API_URL = `${GROQ_BASE_URL}/chat/completions`;
const LMStudio_API_URL = `${LMStudio_BASE_URL}/chat/completions`;
interface ModelInfo {
  id: string;
  name: string;
  pricing: object; 
}

export class LLMService {
  private apiKey: string;
  private defaultModel: string;
  private provider: 'openrouter' | 'groq' | 'lmstudio';

  private completionUrl: string;
  private modelsUrl: string;

  constructor(apiKey: string, defaultModel = 'google/gemini-flash-1.5', service = 'lmstudio') { 
    if (!apiKey) {
      throw new Error("OpenRouter API key is required.");
    }
    this.apiKey = apiKey;
    this.defaultModel = defaultModel;
    this.provider = service as 'openrouter' | 'groq' | 'lmstudio';
    console.log(`${this.provider}Service initialized with model: ${this.defaultModel}`);
    this.completionUrl = service === 'openrouter' ? OPENROUTER_API_URL : service === 'groq' ? GROQ_API_URL : LMStudio_API_URL;
    this.modelsUrl = service === 'openrouter' ? `${OPENROUTER_BASE_URL}/models` : service === 'groq' ? `${GROQ_BASE_URL}/models` : `${LMStudio_BASE_URL}/models`;
  }

  async getAvailableModels(): Promise<ModelInfo[]> {
    try {
      // Prepare headers based on the service type
      const headers: Record<string, string> = {
        'Content-Type': 'application/json', // Often expected, even if not strictly needed for GET
      };

      // Add auth and other headers only if not using LMStudio for the models endpoint
      // LM Studio's /v1/models endpoint typically doesn't require these
      if (this.provider !== 'lmstudio') {
        headers['Authorization'] = `Bearer ${this.apiKey}`;
        headers['HTTP-Referer'] = typeof window !== 'undefined' ? window.location.origin : 'http://localhost';
        headers['X-Title'] = typeof window !== 'undefined' ? window.document.title || 'CV App' : 'CV App (SSR)';
      }
      // For LMStudio, we send only Content-Type by default for the models request.

      const response = await axios.get<{ data: ModelInfo[] }>(this.modelsUrl, {
        headers: headers
      });

      // Filter out any potentially null or invalid model entries more robustly
      return response.data.data.filter(model => model && model.id);

    } catch (error) {
      console.error(`Error fetching models from ${this.provider} (${this.modelsUrl}):`, error);
      // Consider more specific error handling or returning an empty array
      throw error; // Re-throw the error for upstream handling
    }
  }

  async createChatCompletion(request: ChatCompletionRequest): Promise<ChatCompletionResponse> {
    const modelToUse = request.model || this.defaultModel;
    console.log(`Creating chat completion with model: ${modelToUse}`);
    
    if (!request.messages || request.messages.length === 0) {
      throw new Error("Cannot send request with empty messages.");
    }

    // Make sure a multimodal model is selected if sending image data
    const hasImage = request.messages.some(msg => 
      Array.isArray(msg.content) && msg.content.some(part => part.type === 'image_url')
    );
    if (hasImage) {
      console.warn(`Sending image data. Ensure model '${modelToUse}' supports multimodal input.`);
    }

    try {
      const response = await axios.post<ChatCompletionResponse>(
        this.completionUrl,
        {
          ...request, 
          model: modelToUse, 
          stream: false,
        },
        {
          headers: {
            'Authorization': `Bearer ${this.apiKey}`,
            'Content-Type': 'application/json',
            'HTTP-Referer': typeof window !== 'undefined' ? window.location.origin : 'http://localhost',
            'X-Title': typeof window !== 'undefined' ? window.document.title || 'CV App' : 'CV App (SSR)',
          },
        }
      );

      if (!response.data || !Array.isArray(response.data.choices) || response.data.choices.length === 0) {
        throw new Error('Invalid response format: missing or empty choices array');
      }
      
      return response.data; 

    } catch (error) {
      console.error(`Error during OpenRouter chat completion (Model: ${modelToUse}):`, error);
      throw error;
    }
  }
} 